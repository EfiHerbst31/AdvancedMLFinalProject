alpha=0.5
bert_model=bert-base-uncased
cache_dir=./BERT_CACHE/
data_dir=./data/
do_eval=True
do_lower_case=True
do_train=True
eval_batch_size=8
fp16=False
gradient_accumulation_steps=1
learning_rate=5e-06
local_rank=-1
loss_scale=0
max_seq_length=128
no_cuda=False
num_train_epochs=15.0
output_dir=./bert_base_15
seed=42
server_ip=
server_port=
task_name=stance
train_batch_size=8
warmup_proportion=0.1
eval_accuracy = 0.7713667508113956
eval_loss = 1.3927455841099323
global_step = 13125
loss = 0.00604072254044669
              precision    recall  f1-score   support

    supports     0.7624    0.8266    0.7932      1471
     refutes     0.7835    0.7089    0.7444      1302

   micro avg     0.7714    0.7714    0.7714      2773
   macro avg     0.7730    0.7678    0.7688      2773
weighted avg     0.7723    0.7714    0.7703      2773
