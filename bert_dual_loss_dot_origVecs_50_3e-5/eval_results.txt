alpha=0.5
bert_model=bert-base-uncased
cache_dir=./BERT_CACHE/
data_dir=./data/
do_eval=True
do_lower_case=True
do_train=True
eval_batch_size=8
fp16=False
gradient_accumulation_steps=1
learning_rate=3e-05
local_rank=-1
loss_scale=0
max_seq_length=128
no_cuda=False
num_train_epochs=50.0
output_dir=./bert_dual_loss_dot_origVecs_50_3e-5
seed=42
server_ip=
server_port=
task_name=stance
train_batch_size=8
warmup_proportion=0.1
eval_accuracy = 0.7503612716763006
eval_loss = 4.6601269548123625
global_step = 43750
loss = 0.026729044748204096
              precision    recall  f1-score   support

    supports     0.7541    0.7854    0.7694      1468
     refutes     0.7458    0.7108    0.7278      1300

   micro avg     0.7504    0.7504    0.7504      2768
   macro avg     0.7499    0.7481    0.7486      2768
weighted avg     0.7502    0.7504    0.7499      2768
